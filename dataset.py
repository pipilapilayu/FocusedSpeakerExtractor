import os
import random
import torchaudio
import torch
from torch.utils.data import Dataset, DataLoader
from typing import Dict, List, Tuple, Iterable
from glob import glob
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import pytest


def read_wav_44100(filename: str) -> torch.Tensor:
    y, fs = torchaudio.load(filename)
    if y.shape[0] > 1:
        y = torch.mean(y, dim=0, keepdim=True)
    if fs != 44100:
        y = torchaudio.functional.resample(y, fs, 44100)
    return y


class CachedLoader:
    def __init__(self) -> None:
        self.map: Dict[str, torch.Tensor] = {}

    def __getitem__(self, key: str) -> torch.Tensor:
        if key not in self.map:
            self.map[key] = read_wav_44100(key)
        return self.map[key]


MixedAudioDatasetOutput = Tuple[torch.Tensor, torch.Tensor]


class MixedAudioDataset(Dataset):
    """
    Accept clean folder and dirty folders.
    Each time when asked to fetch something, we load, monoize, resample, and cache each file.
    Mixed files are generated by following procedure:
    0. randomly select a clean wav from files in all clean files
    1. randomly select a dirty wav from files in all dirty files
    2. randomly select a start point in dirty wav
    3. chop a segment with length = clean wav
    4. mix, but dirty file got random 0.8-1.2x amp
    5. returns mixed and clean wav
    """

    def __init__(self, clean_folder: str, dirty_folders: List[str]):
        self.clean_folder = clean_folder
        self.dirty_folders = dirty_folders
        self.clean_files = [f for f in glob(os.path.join(clean_folder, "*.wav"))]
        self.dirty_files = [
            f
            for d in dirty_folders
            for f in glob(os.path.join(d, "*.wav"))
            + glob(os.path.join(d, "*.m4a"))
            + glob(os.path.join(d, "*.mp3"))
        ]
        self.cached_loader = CachedLoader()

    def __len__(self):
        return len(self.clean_files)

    @staticmethod
    def overlap_dirty_segment(
        clean_audio: torch.Tensor, dirty_audio: torch.Tensor
    ) -> torch.Tensor:
        # randomly select start point from [0..len(dirty) - len(clean))
        # overlap dirty[start:start + len(clean)]

        # Assert audio is in shape [Channels, Length]
        len_clean = clean_audio.shape[-1]
        len_dirty = dirty_audio.shape[-1]

        if len_dirty < len_clean:
            raise ValueError("Dirty audio must be longer than clean audio.")

        # Randomly select a start point for the dirty audio segment
        start_point = random.randint(0, len_dirty - len_clean)

        dirty_segment = dirty_audio[:, start_point : start_point + len_clean]
        overlapped_audio = clean_audio + random.uniform(0.8, 1.2) * dirty_segment

        return overlapped_audio

    def __getitem__(self, idx: int) -> MixedAudioDatasetOutput:
        """
        Args:
            idx: int, some random index ranging in [0..len(self))
        Returns:
            (
                mixed_wav: 1 x T, torch.Tensor. T is number of samples.
                clean_wav: 1 x T, torch.Tensor
            )
        """
        clean_file = self.clean_files[idx]
        clean_wav = self.cached_loader[clean_file]

        dirty_file = random.choice(self.dirty_files)
        dirty_wav = self.cached_loader[dirty_file]

        mixed_wav = self.overlap_dirty_segment(clean_wav, dirty_wav)

        # mixed_wav = self.overlap_dirty_segment(
        #     clean_wav, (torch.rand_like(clean_wav) * 2 - 1) * 0.01
        # )

        return mixed_wav, clean_wav


def pad_seq_n_stack(wavs: List[torch.Tensor], target_len: int) -> torch.Tensor:
    """
    Args:
        wavs: list of 1 x T torch.Tensor, T may vary.
        target_len: assert to be max T in that varying 1 x T tensor list.
    Returns:
        result: B x target_len torch.Tensor
    """
    padded_wavs = [
        torch.cat([wav, torch.zeros(target_len - len(wav))])
        for wav in map(lambda x: x[0], wavs)
    ]
    return torch.stack(padded_wavs)


MixedAudioDataLoaderOutput = Tuple[torch.Tensor, torch.Tensor, torch.Tensor]


def collate_fn(batch: List[MixedAudioDatasetOutput]) -> MixedAudioDataLoaderOutput:
    """
    Returns:
        (
            batch_padded_mixed_wav: B x T, torch.Tensor
            prepad_lengths: B, torch.Tensor
            batch_padded_clean_wav: B x T, torch.Tensor
        )
    """
    # batch.iter().map(|(mixed, _clean)| mixed.shape.last().unwrap()).collect::<Tensor>()
    prepad_lengths = torch.tensor(
        [mixed.shape[-1] for mixed, _ in batch], dtype=torch.long
    )
    pad_length = int(prepad_lengths.max().item())

    mixed_wavs, clean_wavs = zip(*batch)
    batch_padded_mixed_wav = pad_seq_n_stack(list(mixed_wavs), pad_length)
    batch_padded_clean_wav = pad_seq_n_stack(list(clean_wavs), pad_length)

    return (batch_padded_mixed_wav, prepad_lengths, batch_padded_clean_wav)


class MixedAudioDataLoader(DataLoader):
    def __init__(self, *args, **kwargs):
        super(MixedAudioDataLoader, self).__init__(
            collate_fn=collate_fn, *args, **kwargs
        )


@pytest.fixture
def test_dataset():
    return MixedAudioDataset(
        "./datasets/clean/pi/bootstrap",
        [
            "./datasets/dirty/c_chan/stardew_valley",
            # "./datasets/dirty/c_chan/ratopia",
        ],
    )


def test_dataset_length(test_dataset):
    # Check if dataset length is as expected
    assert len(test_dataset) == 3063


def plot_melspectrogram(wav, ax, fs=44100, title="Melspectrogram"):
    s = librosa.feature.melspectrogram(y=wav, sr=44100)
    librosa.display.specshow(
        librosa.power_to_db(s), x_axis="time", y_axis="mel", ax=ax, sr=fs
    )
    ax.set(title=title)


def test_audio_loading(test_dataset):
    # Test if audio is loaded and resampled correctly
    mixed_wav, clean_wav = test_dataset[0]
    assert mixed_wav is not None
    assert mixed_wav.shape[0] == 1
    assert mixed_wav.shape[1] > 0
    assert isinstance(mixed_wav, torch.Tensor)
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 2))
    ax = axes[0]
    plot_melspectrogram(mixed_wav.squeeze().numpy(), ax, title="mixed")
    ax = axes[1]
    plot_melspectrogram(clean_wav.squeeze().numpy(), ax, title="clean")
    plt.show()


def test_loader(test_dataset):
    loader = MixedAudioDataLoader(test_dataset, batch_size=4)
    for padded_mixed, lengths, padded_clean in loader:
        fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 8))

        for i in range(4):
            # Plot mixed audio
            ax = axes[i, 0]
            plot_melspectrogram(padded_mixed[i].numpy(), ax, title="mixed")

            # Plot clean audio
            ax = axes[i, 1]
            plot_melspectrogram(padded_clean[i].numpy(), ax, title="clean")

        plt.tight_layout()
        plt.show()

        break
